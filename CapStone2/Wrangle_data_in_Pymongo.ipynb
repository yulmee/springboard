{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yulmee\\Anaconda3\\lib\\site-packages\\pymongo\\common.py:555: UserWarning: Unknown option retryWrites\n",
      "  warnings.warn(str(exc))\n"
     ]
    }
   ],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://yulmee_user:CoTaMa!314@cluster0-shard-00-00-dnraj.mongodb.net:27017,cluster0-shard-00-01-dnraj.mongodb.net:27017,cluster0-shard-00-02-dnraj.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin&retryWrites=true&w=majority\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Process News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DB\n",
    "db = client['my_data_feed']\n",
    "# define collection\n",
    "news = db['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Record for the collection: 1520\n"
     ]
    }
   ],
   "source": [
    " print('Total Record for the collection: ' + str(news.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Set up dataframes to hold data\n",
    "For my notes: https://thispointer.com/pandas-how-to-create-an-empty-dataframe-and-append-rows-columns-to-it-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Dataframe \n",
      "Empty DataFrame\n",
      "Columns: [id, title, description, content, URL, createdTimestamp, lang, isRelated, source, sourceDate, NP]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "newsDF = pd.DataFrame(columns=['id', 'title','description', 'content', 'URL', 'createdTimestamp', 'lang','isRelated', 'source','sourceDate', 'NP'])\n",
    "\n",
    "print(\"Empty Dataframe \", newsDF, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Dataframe \n",
      "Empty DataFrame\n",
      "Columns: [id, topic, newsOrTwit]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "topicsDF = pd.DataFrame(columns=['id', 'topic', 'newsOrTwit'])\n",
    "print(\"Empty Dataframe \", topicsDF, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_topics(topicsDF, Topics, newsOrTwit, _id):\n",
    "    if Topics is not None:\n",
    "        topic_list = Topics.split(', ')\n",
    "        for topic in topic_list:\n",
    "            # set newsOrTwit N for news\n",
    "            topicsDF = topicsDF.append({'id':_id, 'topic': topic, 'newsOrTwit': newsOrTwit}, ignore_index=True)\n",
    "    return topicsDF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520\n"
     ]
    }
   ],
   "source": [
    "print(news.find().count())\n",
    "#for article in news.find({\"Source\": \"WF\"}):\n",
    "\n",
    "for article in news.find():\n",
    "    #print(article['_id'])\n",
    "    lang = article.get('lang')\n",
    "    # Process lang\n",
    "    if lang is None: \n",
    "        lang= 'en'\n",
    "    # process createdTimeStamp 2019-09-25T20:15:00Z\n",
    "    newCreatedTimeStamp = article.get('publishedAt').replace(\"T\", \" \")[0:-1]\n",
    "    newCreatedTimeStamp_dt = datetime.strptime(newCreatedTimeStamp, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    source_dt = datetime.strptime(article.get('Source_date'), '%Y-%m-%d' )\n",
    "    \n",
    "    # add to dataframe\n",
    "    newsDF = newsDF.append({'id':article.get('_id'), 'title':article.get('title'),'description':article.get('description'), 'content':article.get('content'), 'URL':article.get('url').strip(), 'createdTimestamp':newCreatedTimeStamp_dt, 'lang':lang,'isRelated':article.get('isRelated'), 'source':article['Source'],'sourceDate':source_dt, 'NP':article.get('NP')}, ignore_index=True)\n",
    "    \n",
    "    # Process topics\n",
    "    Topics = article.get('Topic')\n",
    "    topicsDF = process_topics(topicsDF, Topics, \"N\", article.get('_id'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Process Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe for twitter\n",
    "twitterDF = pd.DataFrame(columns=['id', 'text', 'URL', 'createdTimestamp','quoteCount','replyCount', 'retweetCount', 'favoriteCount', 'isInReplyTo' 'user_id', 'userLocation','userFollowersCount','userFriendsCount', 'lang','isRelated', 'source','sourceDate', 'NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter feed from MongoDB\n",
    "twits = db['twitter_full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_twitter_content(tweet):\n",
    "    # remove urls\n",
    "    #https://stackoverflow.com/questions/24399820/expression-to-remove-url-links-from-twitter-tweet/24399874\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet) \n",
    "    # remove RT (RT @xxxx: )\n",
    "    tweet = re.sub('RT @[\\w_]+: ', '', tweet)\n",
    "    # remove user handle (@WFAssetMgmt)\n",
    "    tweet = re.sub(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)\", \"\", tweet)\n",
    "    # remove # hashtags\n",
    "    tweet = re.sub(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))#([A-Za-z]+[A-Za-z0-9-_]+)\", \"\", tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for twit in twits.find():\n",
    "    # add to dataframe\n",
    "    urls = twit.get('entities').get('urls')\n",
    "    url=None\n",
    "    if len(urls) > 0: \n",
    "        url = urls[0].get('url')\n",
    "    # https://www.programiz.com/python-programming/datetime/strptime\n",
    "    createdAt = twit.get('created_at')\n",
    "    newCreatedTimeStamp_dt = datetime.strptime(createdAt, '%a %b %d %H:%M:%S +%f %Y') \n",
    "    \n",
    "    source_dt=None\n",
    "    if twit.get('Source_date') is not None:\n",
    "        if (twit.get('Source_date') =='2019-09-20'):\n",
    "            print(twit)\n",
    "        source_dt = datetime.strptime(twit.get('Source_date'), '%Y-%m-%d' )\n",
    "    \n",
    "    isInReplyTo = False\n",
    "    if twit.get('in_reply_to_status_id') is not None:\n",
    "        isInReplyTo = True\n",
    "    \n",
    "    tweet_content=twit.get('text')\n",
    "    if tweet_content is not None:\n",
    "        tweet_content=clean_twitter_content(tweet_content)\n",
    "\n",
    "    twitterDF = twitterDF.append({'id':twit.get('_id'), 'text':tweet_content, 'URL': url, 'createdTimestamp': newCreatedTimeStamp_dt, 'quoteCount': twit.get('quote_count'), 'replyCount': twit.get('reply_count'), 'retweetCount': twit.get('retweet_count'), 'favoriteCount': twit.get('favorite_count'), 'isInReplyTo':isInReplyTo, 'user_id': twit.get('user').get('id'),'userLocation': twit.get('user').get('location'), 'userFollowersCount': twit.get('user').get('followers_count'), 'userFriendsCount': twit.get('user').get('friends_count'),'lang':twit.get('lang'),'isRelated':twit.get('isRelated'), 'source':twit.get('Source'),'sourceDate':source_dt, 'NP':twit.get('NP')}, ignore_index=True)\n",
    "    \n",
    "    # Topic\n",
    "    Topics = twit.get('Topic')\n",
    "    topicsDF = process_topics(topicsDF, Topics, \"T\", twit.get('_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove Duplicates - News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsDF.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsDF.sort_values(by=['URL','createdTimestamp'])\n",
    "#twitterDF.sort_values(by=['id'])\n",
    "#topicsDF.sort_values(by=['id', 'topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsDF.drop_duplicates(['URL','createdTimestamp'], keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save results to file for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv to read in at different notebook\n",
    "#newsDF.to_csv('news.csv')\n",
    "#topicsDF.to_csv('topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitterDF.to_csv('twitter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
